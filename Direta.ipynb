{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b1b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8663bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DadosHistoricos_Ibovespa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd391b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Último</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Máxima</th>\n",
       "      <th>Mínima</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Var%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.06.2025</td>\n",
       "      <td>139.256</td>\n",
       "      <td>137.212</td>\n",
       "      <td>139.988</td>\n",
       "      <td>137.212</td>\n",
       "      <td>7,62M</td>\n",
       "      <td>1,49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.06.2025</td>\n",
       "      <td>137.213</td>\n",
       "      <td>137.800</td>\n",
       "      <td>137.800</td>\n",
       "      <td>136.586</td>\n",
       "      <td>8,63B</td>\n",
       "      <td>-0,43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.06.2025</td>\n",
       "      <td>137.800</td>\n",
       "      <td>137.127</td>\n",
       "      <td>137.931</td>\n",
       "      <td>136.175</td>\n",
       "      <td>7,12B</td>\n",
       "      <td>0,49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.06.2025</td>\n",
       "      <td>137.128</td>\n",
       "      <td>136.443</td>\n",
       "      <td>137.531</td>\n",
       "      <td>135.628</td>\n",
       "      <td>8,77B</td>\n",
       "      <td>0,51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.06.2025</td>\n",
       "      <td>136.436</td>\n",
       "      <td>135.716</td>\n",
       "      <td>137.369</td>\n",
       "      <td>135.716</td>\n",
       "      <td>8,19B</td>\n",
       "      <td>0,54%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data   Último  Abertura   Máxima   Mínima   Vol.    Var%\n",
       "0  16.06.2025  139.256   137.212  139.988  137.212  7,62M   1,49%\n",
       "1  13.06.2025  137.213   137.800  137.800  136.586  8,63B  -0,43%\n",
       "2  12.06.2025  137.800   137.127  137.931  136.175  7,12B   0,49%\n",
       "3  11.06.2025  137.128   136.443  137.531  135.628  8,77B   0,51%\n",
       "4  10.06.2025  136.436   135.716  137.369  135.716  8,19B   0,54%"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f33cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão object para data sem horario\n",
    "df[\"Data\"] = pd.to_datetime(df['Data'], format='%d.%m.%Y', dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "df.sort_values(by='Data', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197ad452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Último</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Máxima</th>\n",
       "      <th>Mínima</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Var%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2015-06-15</td>\n",
       "      <td>53.138</td>\n",
       "      <td>53.338</td>\n",
       "      <td>53.338</td>\n",
       "      <td>52.548</td>\n",
       "      <td>2,69M</td>\n",
       "      <td>-0,39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>53.702</td>\n",
       "      <td>53.144</td>\n",
       "      <td>53.969</td>\n",
       "      <td>53.107</td>\n",
       "      <td>3,38M</td>\n",
       "      <td>1,06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>53.249</td>\n",
       "      <td>53.698</td>\n",
       "      <td>53.755</td>\n",
       "      <td>52.965</td>\n",
       "      <td>3,09M</td>\n",
       "      <td>-0,84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>54.239</td>\n",
       "      <td>53.251</td>\n",
       "      <td>54.352</td>\n",
       "      <td>53.214</td>\n",
       "      <td>2,75M</td>\n",
       "      <td>1,86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>53.749</td>\n",
       "      <td>54.236</td>\n",
       "      <td>54.236</td>\n",
       "      <td>53.479</td>\n",
       "      <td>2,95M</td>\n",
       "      <td>-0,90%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data  Último  Abertura  Máxima  Mínima   Vol.    Var%\n",
       "2481  2015-06-15  53.138    53.338  53.338  52.548  2,69M  -0,39%\n",
       "2480  2015-06-16  53.702    53.144  53.969  53.107  3,38M   1,06%\n",
       "2479  2015-06-17  53.249    53.698  53.755  52.965  3,09M  -0,84%\n",
       "2478  2015-06-18  54.239    53.251  54.352  53.214  2,75M   1,86%\n",
       "2477  2015-06-19  53.749    54.236  54.236  53.479  2,95M  -0,90%"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2488dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_volume(vol):\n",
    "    try:\n",
    "        vol = str(vol).replace('.', '').replace(',', '.').strip().upper()\n",
    "        if 'K' in vol:\n",
    "            return float(vol.replace('K', '')) * 1e3\n",
    "        elif 'M' in vol:\n",
    "            return float(vol.replace('M', '')) * 1e6\n",
    "        elif 'B' in vol:\n",
    "            return float(vol.replace('B', '')) * 1e9\n",
    "        else:\n",
    "            return float(vol)\n",
    "    except:\n",
    "        return None  # ou 0, se preferir não deixar NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "776d7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Vol.'] = df['Vol.'].apply(lambda x: parse_volume(x) if pd.notnull(x) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de1ef328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Último</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Máxima</th>\n",
       "      <th>Mínima</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Var%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2015-06-15</td>\n",
       "      <td>53.138</td>\n",
       "      <td>53.338</td>\n",
       "      <td>53.338</td>\n",
       "      <td>52.548</td>\n",
       "      <td>2690000.0</td>\n",
       "      <td>-0,39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>53.702</td>\n",
       "      <td>53.144</td>\n",
       "      <td>53.969</td>\n",
       "      <td>53.107</td>\n",
       "      <td>3380000.0</td>\n",
       "      <td>1,06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>53.249</td>\n",
       "      <td>53.698</td>\n",
       "      <td>53.755</td>\n",
       "      <td>52.965</td>\n",
       "      <td>3090000.0</td>\n",
       "      <td>-0,84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>54.239</td>\n",
       "      <td>53.251</td>\n",
       "      <td>54.352</td>\n",
       "      <td>53.214</td>\n",
       "      <td>2750000.0</td>\n",
       "      <td>1,86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>53.749</td>\n",
       "      <td>54.236</td>\n",
       "      <td>54.236</td>\n",
       "      <td>53.479</td>\n",
       "      <td>2950000.0</td>\n",
       "      <td>-0,90%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data  Último  Abertura  Máxima  Mínima       Vol.    Var%\n",
       "2481  2015-06-15  53.138    53.338  53.338  52.548  2690000.0  -0,39%\n",
       "2480  2015-06-16  53.702    53.144  53.969  53.107  3380000.0   1,06%\n",
       "2479  2015-06-17  53.249    53.698  53.755  52.965  3090000.0  -0,84%\n",
       "2478  2015-06-18  54.239    53.251  54.352  53.214  2750000.0   1,86%\n",
       "2477  2015-06-19  53.749    54.236  54.236  53.479  2950000.0  -0,90%"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad27ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variação percentual diária do fechamento\n",
    "# capturar o “ritmo” de alta ou baixa. Uma variação muito positiva ou negativa pode indicar tendência.\n",
    "\n",
    "df['pct_change'] = df['Último'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de1f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicadores técnicos: RSI (14 dias)\n",
    "from ta.momentum import RSIIndicator\n",
    "\n",
    "rsi = RSIIndicator(close=df['Último'], window=14)\n",
    "df['rsi_14'] = rsi.rsi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac3e3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD - diferenaça entre as medias moveis de curto e longo prazo, que mostra reversão ou continuação de tendência.\n",
    "from ta.trend import MACD\n",
    "\n",
    "macd = MACD(close=df['Último'])\n",
    "df['macd'] = macd.macd()\n",
    "df['macd_signal'] = macd.macd_signal()\n",
    "df['macd_diff'] = macd.macd_diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7440fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lags do fechamento - capturar o histórico recente, como se você estivesse \"olhando para trás\" para tomar a decisão de amanhã.\n",
    "df['lag_1'] = df['Último'].shift(1)\n",
    "df['lag_2'] = df['Último'].shift(2)\n",
    "df['lag_3'] = df['Último'].shift(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fd60ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variável target (alvo) - É o que vamos prever: se o IBOV vai subir no próximo dia.\n",
    "df['target'] = (df['Último'].shift(-1) > df['Último']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dd04db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando dados após algumas ccriações para eliminar os NaN que temos nas primeiras e ultimas linhas da base\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0a12f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando treino e teste\n",
    "# 1) Garantir que o DataFrame esteja ordenado por data\n",
    "df = df.sort_values('Data').reset_index(drop=True)\n",
    "\n",
    "# 2) Definir tamanho do teste (últimos 30 dias)\n",
    "test_size = 30\n",
    "\n",
    "# 3) Criar df_train e df_test\n",
    "df_train = df.iloc[:-test_size].copy()\n",
    "df_test  = df.iloc[-test_size:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "852e3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo x e y\n",
    "feature_cols = [\n",
    "    'pct_change', 'rsi_14', 'macd', 'macd_signal', 'macd_diff',\n",
    "    'lag_1', 'lag_2', 'lag_3'\n",
    "]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train['target']\n",
    "\n",
    "X_test  = df_test[feature_cols]\n",
    "y_test  = df_test['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6421f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2418, 8) (30, 8)\n",
      "[ True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)  \n",
    "print(X_train.columns == X_test.columns)  # deve ser all True  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae333a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o Random Forest (baseline)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics   import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1) Instanciar o modelo com parâmetros default\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2) Treinar\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 3) Prever no conjunto de teste\n",
    "y_pred = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d4e383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia baseline: 50.00%\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[13  2]\n",
      " [13  2]] \n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.87      0.63        15\n",
      "           1       0.50      0.13      0.21        15\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.50      0.50      0.42        30\n",
      "weighted avg       0.50      0.50      0.42        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do desempenho\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia baseline: {acc:.2%}\\n\")\n",
    "\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acdd481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando media moveis \n",
    "# Janela de 5, 10 e 20 dias sobre o fechamento\n",
    "df['ma_5']  = df['Último'].rolling(window=5).mean()\n",
    "df['ma_10'] = df['Último'].rolling(window=10).mean()\n",
    "df['ma_20'] = df['Último'].rolling(window=20).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "706b9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distância do preço às médias\n",
    "df['close_vs_ma5']  = df['Último'] - df['ma_5']\n",
    "df['close_vs_ma20'] = df['Último'] - df['ma_20']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a28116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diferença entre médias (crossover)\n",
    "df['diff_ma5_ma10']   = df['ma_5']  - df['ma_10']\n",
    "df['diff_ma10_ma20']  = df['ma_10'] - df['ma_20']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5e44207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzamento do MACD\n",
    "df['macd_cross'] = df['macd'] - df['macd_signal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a37823ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando os NaN\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47a5b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'pct_change',    # variação percentual\n",
    "    'rsi_14',        # RSI 14\n",
    "    'macd',          # MACD\n",
    "    'macd_signal',   # sinal do MACD\n",
    "    'macd_diff',     # histograma MACD\n",
    "    'lag_1',         # fechamento t-1\n",
    "    'lag_2',         # fechamento t-2\n",
    "    'lag_3',         # fechamento t-3\n",
    "    'close_vs_ma5',\n",
    "    'close_vs_ma20',\n",
    "    'diff_ma5_ma10',\n",
    "    'diff_ma10_ma20',\n",
    "    'macd_cross'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e805e264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 46.67%\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[11  4]\n",
      " [12  3]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.73      0.58        15\n",
      "           1       0.43      0.20      0.27        15\n",
      "\n",
      "    accuracy                           0.47        30\n",
      "   macro avg       0.45      0.47      0.43        30\n",
      "weighted avg       0.45      0.47      0.43        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.1) Ordenar e dividir\n",
    "df = df.sort_values('Data').reset_index(drop=True)\n",
    "test_size = 30\n",
    "df_train = df.iloc[:-test_size]\n",
    "df_test  = df.iloc[-test_size:]\n",
    "\n",
    "# 5.2) X e y\n",
    "X_train = df_train[feature_cols];  y_train = df_train['target']\n",
    "X_test  = df_test[feature_cols];   y_test  = df_test['target']\n",
    "\n",
    "# 5.3) Treinar e prever\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics   import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# 5.4) Avaliar\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(\"\\nMatriz de Confusão:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcd16cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# já temos df ordenado e com pct_change\n",
    "window = 5\n",
    "\n",
    "for i in range(1, window+1):\n",
    "    df[f\"ret_{i}\"] = df['pct_change'].shift(i)\n",
    "\n",
    "# Target permanece:\n",
    "df['target'] = (df['Último'].shift(-1) > df['Último']).astype(int)\n",
    "\n",
    "# Remover NaNs\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11891fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [f\"ret_{i}\" for i in range(1, window+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e17b8ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia baseline (lags): 0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 2.1) Separar treino/teste\n",
    "test_size = 30\n",
    "df_train = df.iloc[:-test_size]\n",
    "df_test  = df.iloc[-test_size:]\n",
    "\n",
    "X_train = df_train[feature_cols];  y_train = df_train['target']\n",
    "X_test  = df_test[feature_cols];   y_test  = df_test['target']\n",
    "\n",
    "# 2.2) Treinar Random Forest simples\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics   import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Acurácia baseline (lags):\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a721bc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia tunada (lags): 53.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.12        15\n",
      "           1       0.52      1.00      0.68        15\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.76      0.53      0.40        30\n",
      "weighted avg       0.76      0.53      0.40        30\n",
      "\n",
      "Parâmetros ótimos: {'n_estimators': 100, 'min_samples_split': 4, 'max_features': 'log2', 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_dist = {\n",
    "    'n_estimators':    [100,200,300],\n",
    "    'max_depth':       [4,6,8,None],\n",
    "    'min_samples_split':[2,4,6],\n",
    "    'max_features':    ['sqrt','log2']\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20, cv=tscv,\n",
    "    scoring='accuracy', n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(X_train, y_train)\n",
    "best_rf = rs.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(f\"Acurácia tunada (lags): {accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Parâmetros ótimos:\", rs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8642fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Acurácia XGBoost tunado: 60.00%\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[ 8  7]\n",
      " [ 5 10]] \n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57        15\n",
      "           1       0.59      0.67      0.62        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "Melhores parâmetros XGBoost: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:35:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1.1) Defina o mesmo X_train, y_train, X_test, y_test dos lags\n",
    "# já está no seu notebook\n",
    "\n",
    "# 1.2) Configure a validação temporal\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 1.3) Espaço de busca para o XGBoost\n",
    "param_dist_xgb = {\n",
    "    'n_estimators':    [50,100,200],\n",
    "    'max_depth':       [3, 5, 7, 9],\n",
    "    'learning_rate':   [0.01, 0.05, 0.1],\n",
    "    'subsample':       [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree':[0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# 1.4) RandomizedSearchCV\n",
    "rs_xgb = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=20,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs_xgb.fit(X_train, y_train)\n",
    "\n",
    "# 1.5) Avaliar no conjunto de teste\n",
    "best_xgb = rs_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "print(f\"Acurácia XGBoost tunado: {accuracy_score(y_test, y_pred_xgb):.2%}\\n\")\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_xgb), \"\\n\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "print(\"Melhores parâmetros XGBoost:\", rs_xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e25ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Stacking: 50.00%\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[ 1 14]\n",
      " [ 1 14]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.07      0.12        15\n",
      "           1       0.50      0.93      0.65        15\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.50      0.50      0.38        30\n",
      "weighted avg       0.50      0.50      0.38        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# supondo que best_rf_params e best_xgb_params já existam\n",
    "estimators = [\n",
    "    ('rf',  RandomForestClassifier(**best_rf_params, random_state=42)),\n",
    "    ('xgb', XGBClassifier(**best_xgb_params, use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=kf,          # agora um CV particionado\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stack.fit(X_train, y_train)\n",
    "y_pred_stack = stack.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(f\"Acurácia Stacking: {accuracy_score(y_test, y_pred_stack):.2%}\\n\")\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_stack))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred_stack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68a8a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    n_jobs=-1\n",
    ")\n",
    "# ou explicitamente: cv=5\n",
    "# stack = StackingClassifier(..., cv=5, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3ca3c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473 linhas sem data válida\n"
     ]
    }
   ],
   "source": [
    "# 1) Converter Data para datetime (inferência automática)\n",
    "df['Data'] = pd.to_datetime(df['Data'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Verifique se não há conversões que falharam\n",
    "print(df['Data'].isna().sum(), \"linhas sem data válida\")\n",
    "\n",
    "# 2) Agora os atributos de calendário funcionarão\n",
    "df['weekday'] = df['Data'].dt.weekday    # 0=segunda … 6=domingo\n",
    "df['month']   = df['Data'].dt.month      # 1 a 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "994d9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Volume: média móvel e variação\n",
    "df['vol_ma_5']       = df['Vol.'].rolling(window=5).mean()\n",
    "df['vol_pct_change'] = df['Vol.'].pct_change() * 100\n",
    "\n",
    "# 4) Bollinger Bands simples (20 dias)\n",
    "df['bb_upper'] = df['ma_20'] + 2 * df['Último'].rolling(20).std()\n",
    "df['bb_lower'] = df['ma_20'] - 2 * df['Último'].rolling(20).std()\n",
    "\n",
    "# 5) Remover NaNs gerados e resetar índice\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "855f43d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data              datetime64[ns]\n",
      "Último                   float64\n",
      "Abertura                 float64\n",
      "Máxima                   float64\n",
      "Mínima                   float64\n",
      "Vol.                     float64\n",
      "Var%                      object\n",
      "pct_change               float64\n",
      "rsi_14                   float64\n",
      "macd                     float64\n",
      "macd_signal              float64\n",
      "macd_diff                float64\n",
      "lag_1                    float64\n",
      "lag_2                    float64\n",
      "lag_3                    float64\n",
      "target                     int32\n",
      "ma_5                     float64\n",
      "ma_10                    float64\n",
      "ma_20                    float64\n",
      "close_vs_ma5             float64\n",
      "close_vs_ma20            float64\n",
      "diff_ma5_ma10            float64\n",
      "diff_ma10_ma20           float64\n",
      "macd_cross               float64\n",
      "ret_1                    float64\n",
      "ret_2                    float64\n",
      "ret_3                    float64\n",
      "ret_4                    float64\n",
      "ret_5                    float64\n",
      "weekday                  float64\n",
      "month                    float64\n",
      "vol_ma_5                 float64\n",
      "vol_pct_change           float64\n",
      "bb_upper                 float64\n",
      "bb_lower                 float64\n",
      "dtype: object\n",
      "\n",
      "Features usadas:\n",
      " ['pct_change', 'rsi_14', 'macd', 'macd_signal', 'macd_diff', 'lag_1', 'lag_2', 'lag_3', 'weekday', 'month', 'vol_ma_5', 'vol_pct_change', 'bb_upper', 'bb_lower']\n"
     ]
    }
   ],
   "source": [
    "# 1) Verificar tipos de dado\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2) Montar a lista de features\n",
    "feature_cols = [\n",
    "    'pct_change',    # variação percentual diária\n",
    "    'rsi_14',        # RSI 14\n",
    "    'macd',          # MACD\n",
    "    'macd_signal',   # sinal MACD\n",
    "    'macd_diff',     # histograma MACD\n",
    "    'lag_1',         # fechamento t-1\n",
    "    'lag_2',         # fechamento t-2\n",
    "    'lag_3',         # fechamento t-3\n",
    "    'weekday',       # dia da semana\n",
    "    'month',         # mês\n",
    "    'vol_ma_5',      # média móvel volume 5 dias\n",
    "    'vol_pct_change',# variação percentual do volume\n",
    "    'bb_upper',      # Bollinger Upper\n",
    "    'bb_lower'       # Bollinger Lower\n",
    "]\n",
    "\n",
    "# 3) Exibir a lista\n",
    "print(\"\\nFeatures usadas:\\n\", feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f7d5ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Number of positive: 489, number of negative: 426\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3080\n",
      "[LightGBM] [Info] Number of data points in the train set: 915, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.534426 -> initscore=0.137923\n",
      "[LightGBM] [Info] Start training from score 0.137923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Acurácia LightGBM tunado: 66.67%\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[ 8  6]\n",
      " [ 4 12]] \n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        14\n",
      "           1       0.67      0.75      0.71        16\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.67      0.66      0.66        30\n",
      "weighted avg       0.67      0.67      0.66        30\n",
      "\n",
      "Melhores parâmetros LightGBM: {'subsample': 0.6, 'num_leaves': 63, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics       import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1) Separar treino/teste\n",
    "test_size = 30\n",
    "df_train = df.iloc[:-test_size].copy()\n",
    "df_test  = df.iloc[-test_size:].copy()\n",
    "\n",
    "X_train, y_train = df_train[feature_cols], df_train['target']\n",
    "X_test,  y_test  = df_test[feature_cols],  df_test['target']\n",
    "\n",
    "# 2) Configurar TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 3) Definir espaço de busca LightGBM\n",
    "param_dist_lgb = {\n",
    "    'n_estimators':     [50, 100, 200, 300],\n",
    "    'max_depth':        [3, 5, 7, 9, -1],\n",
    "    'learning_rate':    [0.01, 0.05, 0.1, 0.2],\n",
    "    'num_leaves':       [15, 31, 63],\n",
    "    'subsample':        [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "lgb_base = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# 4) RandomizedSearchCV\n",
    "rs_lgb = RandomizedSearchCV(\n",
    "    estimator=lgb_base,\n",
    "    param_distributions=param_dist_lgb,\n",
    "    n_iter=30,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5) Treinar a busca\n",
    "rs_lgb.fit(X_train, y_train)\n",
    "\n",
    "# 6) Avaliar no teste\n",
    "best_lgb = rs_lgb.best_estimator_\n",
    "y_pred_lgb = best_lgb.predict(X_test)\n",
    "\n",
    "print(f\"Acurácia LightGBM tunado: {accuracy_score(y_test, y_pred_lgb):.2%}\\n\")\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_lgb), \"\\n\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_lgb))\n",
    "print(\"Melhores parâmetros LightGBM:\", rs_lgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41d18f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Ensemble: 50.00%\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[ 5  9]\n",
      " [ 6 10]] \n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.36      0.40        14\n",
      "           1       0.53      0.62      0.57        16\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.49      0.49      0.49        30\n",
      "weighted avg       0.49      0.50      0.49        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Supondo que você já tenha best_lgb e best_xgb do RandomizedSearchCV:\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lgb', best_lgb),\n",
    "        ('xgb', best_xgb)\n",
    "    ],\n",
    "    voting='soft',  # usa probabilidades\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treine e avalie\n",
    "voting.fit(X_train, y_train)\n",
    "y_pred_vote = voting.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Acurácia Ensemble: {accuracy_score(y_test, y_pred_vote):.2%}\\n\")\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred_vote), \"\\n\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_vote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6911e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia MLP: 53.33%\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.57      0.53        14\n",
      "           1       0.57      0.50      0.53        16\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.54      0.54      0.53        30\n",
      "weighted avg       0.54      0.53      0.53        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "mlp = make_pipeline(\n",
    "    StandardScaler(),                # normaliza as features\n",
    "    MLPClassifier(\n",
    "        hidden_layer_sizes=(64,32),  # duas camadas ocultas\n",
    "        activation='relu',\n",
    "        alpha=1e-4,                  # regularização L2\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Treine e avalie\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "print(f\"Acurácia MLP: {accuracy_score(y_test, y_pred_mlp):.2%}\\n\")\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df06ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1.1 Defina o tamanho da janela (quantos dias de histórico usar)\n",
    "window_size = 10\n",
    "\n",
    "# 1.2 Selecione as colunas que vai usar (exemplo: pct_change + lags + indicadores)\n",
    "seq_features = feature_cols  # as 14 features que você já montou\n",
    "\n",
    "# 1.3 Escalar os dados entre 0 e 1 (importante para redes neurais)\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[seq_features]),\n",
    "                         columns=seq_features)\n",
    "\n",
    "# 1.4 Criar X, y como sequências\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(window_size, len(df_scaled)-1):\n",
    "    X_seq.append(df_scaled.iloc[i-window_size:i].values)\n",
    "    y_seq.append(df['target'].iloc[i])  # target do dia i\n",
    "\n",
    "X_seq = np.array(X_seq)   # shape = (samples, window_size, n_features)\n",
    "y_seq = np.array(y_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6fa63c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 10, 14) (30, 10, 14)\n"
     ]
    }
   ],
   "source": [
    "# Vamos usar os últimos 30 exemplos como teste\n",
    "test_samples = 30\n",
    "X_train_seq, X_test_seq = X_seq[:-test_samples], X_seq[-test_samples:]\n",
    "y_train_seq, y_test_seq = y_seq[:-test_samples], y_seq[-test_samples:]\n",
    "\n",
    "print(X_train_seq.shape, X_test_seq.shape)  # conferir formatos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "444a5738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 - 3s - 63ms/step - accuracy: 0.5043 - loss: 0.6959 - val_accuracy: 0.5824 - val_loss: 0.6825\n",
      "Epoch 2/50\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.5203 - loss: 0.6940 - val_accuracy: 0.5824 - val_loss: 0.6825\n",
      "Epoch 3/50\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.5117 - loss: 0.6945 - val_accuracy: 0.5824 - val_loss: 0.6898\n",
      "Epoch 4/50\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.5092 - loss: 0.6945 - val_accuracy: 0.5824 - val_loss: 0.6863\n",
      "Epoch 5/50\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.4822 - loss: 0.6959 - val_accuracy: 0.5824 - val_loss: 0.6851\n",
      "Epoch 6/50\n",
      "51/51 - 0s - 7ms/step - accuracy: 0.5301 - loss: 0.6932 - val_accuracy: 0.5824 - val_loss: 0.6902\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "n_features = X_train_seq.shape[2]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(window_size, n_features), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[es],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83006b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia LSTM: 56.67%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
      "Matriz de Confusão:\n",
      " [[ 0 13]\n",
      " [ 0 17]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.57      1.00      0.72        17\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.28      0.50      0.36        30\n",
      "weighted avg       0.32      0.57      0.41        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
    "print(f\"Acurácia LSTM: {acc:.2%}\")\n",
    "\n",
    "# Se quiser matriz de confusão:\n",
    "y_pred_seq = (model.predict(X_test_seq) > 0.5).astype(int).flatten()\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test_seq, y_pred_seq))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test_seq, y_pred_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ee26ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def build_lstm_model(hp):\n",
    "    window = hp.Int('window_size', min_value=5, max_value=20, step=5)\n",
    "    n_layers = hp.Int('n_layers', 1, 3)\n",
    "    lr = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    dropout_rate = hp.Float('dropout', 0.1, 0.5, step=0.1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        return_seq = (i < n_layers - 1)\n",
    "        units = hp.Int(f'units_{i}', min_value=16, max_value=128, step=16)\n",
    "        if i == 0:\n",
    "            model.add(LSTM(units, \n",
    "                           input_shape=(window, len(feature_cols)), \n",
    "                           return_sequences=return_seq))\n",
    "        else:\n",
    "            model.add(LSTM(units, return_sequences=return_seq))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c804217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(df, feature_cols, window):\n",
    "    data = df[feature_cols].values\n",
    "    targets = df['target'].values\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(data)-1):\n",
    "        X.append(data[i-window:i])\n",
    "        y.append(targets[i])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6816c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_lstm_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory='lstm_tuning',\n",
    "    project_name='ibovespa'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a75710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 – Depois de criar dollar['pct_change_usd'], extraia só a Series:\n",
    "pct_usd = dollar['pct_change_usd']  # isso garante que seja um objeto de nível único\n",
    "\n",
    "# 1.2 – Mapeie pela data\n",
    "df['pct_change_usd'] = df['Data'].map(pct_usd)\n",
    "\n",
    "# Pronto: toda vez que df['Data'] coincidir com um índice de pct_usd, ele traz o valor,\n",
    "# senão fica NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6bf2e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_9096\\479131839.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  dollar = yf.download(\"USDBRL=X\", start=\"2018-01-01\", end=\"2025-06-17\", interval=\"1d\")\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Not allowed to merge between different levels. (1 levels on the left, 2 on the right)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMergeError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m dollar[\u001b[33m'\u001b[39m\u001b[33mpct_change_usd\u001b[39m\u001b[33m'\u001b[39m] = dollar[\u001b[33m'\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m'\u001b[39m].pct_change() * \u001b[32m100\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Merge no seu df principal via Data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdollar\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpct_change_usd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mData\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10813\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10814\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10828\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10829\u001b[39m ) -> DataFrame:\n\u001b[32m  10830\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10833\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10836\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10837\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10839\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10841\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10842\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10846\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gusta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:784\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _left.columns.nlevels != _right.columns.nlevels:\n\u001b[32m    779\u001b[39m     msg = (\n\u001b[32m    780\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNot allowed to merge between different levels. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_left.columns.nlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m levels on the left, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    782\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_right.columns.nlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on the right)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    783\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[32m    786\u001b[39m \u001b[38;5;28mself\u001b[39m.left_on, \u001b[38;5;28mself\u001b[39m.right_on = \u001b[38;5;28mself\u001b[39m._validate_left_right_on(left_on, right_on)\n\u001b[32m    788\u001b[39m (\n\u001b[32m    789\u001b[39m     \u001b[38;5;28mself\u001b[39m.left_join_keys,\n\u001b[32m    790\u001b[39m     \u001b[38;5;28mself\u001b[39m.right_join_keys,\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m     right_drop,\n\u001b[32m    794\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._get_merge_keys()\n",
      "\u001b[31mMergeError\u001b[39m: Not allowed to merge between different levels. (1 levels on the left, 2 on the right)"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Baixar série do Dólar\n",
    "dollar = yf.download(\"USDBRL=X\", start=\"2018-01-01\", end=\"2025-06-17\", interval=\"1d\")\n",
    "dollar['pct_change_usd'] = dollar['Close'].pct_change() * 100\n",
    "\n",
    "# Merge no seu df principal via Data\n",
    "df = df.merge(dollar[['pct_change_usd']], left_on='Data', right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c9f262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
